= Analytics using the SDK
:description: Parallel data management for complex queries over many records, using a familiar N1QL-like syntax.
:navtitle: Analytics using the SDK
:page-topic-type: howto
:page-aliases: analytics-query
:page-edition: Enterprise Edition
:lang: Python
:version: 3.2.0
:example-source: 3.2@python-sdk:howtos:example$analytics_ops.py
:example-source-lang: Python

include::project-docs:partial$attributes.adoc[]

[abstract]
{description}

For complex and long-running queries, involving large ad hoc join, set, aggregation, and grouping operations, the Couchbase Data Platform offers the xref:{version-server}@server:analytics:introduction.adoc[Couchbase Analytics Service (CBAS)].
This is the analytic counterpart to our xref:n1ql-queries-with-sdk.adoc[operational data focussed Query Service].
The analytics service is available in Couchbase Data Platform 6.0 and later.

== Getting Started

After familiarizing yourself with our xref:{version-server}@server:analytics:primer-beer.adoc[introductory primer],
in particular creating a dataset and linking it to a bucket, try Couchbase Analytics using the Python SDK.
Intentionally, the API for analytics is nearly identical to that of the query service.

Here's a complete example of doing a analytics and handling the results:

[source,py]
----
include::howtos:example$analytics_ops.py[tag=analytics_basic_example]
----

NOTE: When using a Couchbase version < 6.5 you must create a valid Bucket connection using `cluster.bucket(name)` before you can use Analytics.

Let's break it down. An analytics query is always performed at the `Cluster` level, using the `analytics_query` method. It takes the statement as a required argument and then allows to provide additional options if needed.

Once a result returns you can iterate the returned rows and/or access the `AnalyticsMetaData` associated with the query.

== Parameterized Queries
Supplying parameters as individual arguments to the query allows the analytics engine to optimize the parsing and planning of the query. You can either supply these parameters by name or by position.

The first example shows how to provide them by name:

.Positional parameter example:
[source,python]
----
include::howtos:example$analytics_ops.py[tag=positional]
----

[source,python]
----
include::howtos:example$analytics_ops.py[tag=positional_options]
----

.Named parameter example:
[source,python]
----
include::howtos:example$analytics_ops.py[tag=named_kwargs]
----

[source,python]
----
include::howtos:example$analytics_ops.py[tag=named_options]
----

The complete code for this page's example can be found at https://github.com/couchbase/docs-sdk-python/blob/release/3.2/modules/howtos/examples/analytics_ops.py[analytics_ops.py].
What style you choose is up to you, for readability in more complex queries we generally recommend using the named parameters.
Note that you cannot use parameters in all positions.
If you put it in an unsupported place the server will respond with a `CompilationFailedException` or similar.


== The Analytics Result

When performing an analytics query, the response you receive is an `AnalyticsResult`. If no exception gets raised the request succeeded and provides access to both the rows returned and also associated `AnalyticsMetaData`.

[source,python]
----
include::howtos:example$analytics_ops.py[tag=iterating]
----

The `AnalyticsMetaData` provides insight into some basic profiling/timing information as well as information like the `clientContextId`.

.AnalyticsMetaData
[options="header"]
|====
| Name       | Description
| `request_id() -> str` | Returns the request identifer of this request.
| `client_context_id() -> str` | Returns the context ID either generated by the SDK or supplied by the user.
| `status() -> AnalyticsStatus` | An enum simply representing the state of the result.
| `metrics() -> Optional[AnalyticsMetrics]` | Returns metrics provided by analytics for the request.
| `signature() -> Optional[JSON]` | If a signature is present, it will be available to consume in a generic fashion.
| `warnings() -> Iterable[AnalyticsWarning]` | Non-fatal errors are available to consume as warnings on this method.
|====

For example, here is how you can print the `executionTime` of a query:

[source,python]
----
include::howtos:example$analytics_ops.py[tag=print_metrics]
----

== Analytics Options
The analytics service provides an array of options to customize your query. The following table lists them all:

.Available Analytics Options
[options="header"]
|====
| Name       | Description
| `client_context_id: str` | Sets a context ID returned by the service for debugging purposes.
| `positional_parameters: Iterable[str]` | Allows to set positional arguments for a parameterized query.
| `named_parameters: Dict[str,str]` | Allows to set named arguments for a parameterized query.
| `priority: bool` | Assigns a different server-side priority to the query.
| `raw: Dict[str, Any]` | Escape hatch to add arguments that are not covered by these options.
| `read_only: bool` | Tells the client and server that this query is readonly.
| `scan_consistency: AnalyticsScanConsistency` | Sets a different scan consistency for this query.
|====

=== Scan Consistency

By default, the analytics engine will return whatever is currently in the index at the time of query (this mode is also called `AnalyticsScanConsistency.NOT_BOUNDED`). If you need to include everything that has just been written, a different scan consistency must be chosen. If `AnalyticsScanConsistency.REQUEST_PLUS` is chosen, it will likely take a bit longer to return the results but the analytics engine will make sure that it is as up-to-date as possible.

[source,py]
----
include::howtos:example$analytics_ops.py[tag=scan_consistency]
----

=== Client Context Id

The SDK will always send a client context ID with each query, even if none is provided by the user. By default a UUID will be generated that is mirrored back from the analytics engine and can be used for debugging purposes. A custom string can always be provided if you want to introduce application-specific semantics into it (so that for example in a network dump it shows up with a certain identifier). Whatever is chosen, we recommend making sure it is unique so different queries can be distinguished during debugging or monitoring.

[source,python]
----
include::howtos:example$analytics_ops.py[tag=client_context_id]
----


=== Priority

By default, every analytics query has the same priority on the server. By setting this boolean flag to true, you are indicating that you need expedited dispatch in the analytice engine for this request.

[source,python]
----
include::howtos:example$analytics_ops.py[tag=priority]
----


=== Readonly

If the query is marked as readonly, both the server and the SDK can improve processing of the operation. On the client side, the SDK can be more liberal with retries because it can be sure that there are no state-mutating side-effects happening. The query engine will ensure that actually no data is mutated when parsing and planning the query.

[source,python]
----
include::howtos:example$analytics_ops.py[tag=read_only]
----

////
TODO:  can provide once transcoders/serializers are available w/in SDK

=== Custom JSON Serializer

Like with all JSON apis, it is possible to customize the JSON serializer. It allows to plug in your own library. This in turn makes it possible to serialize rows into PODs or other structures that your application defines and the SDK has no idea about.

Please see the documentation transcoding and serialization for more information.
////

== Async APIs

In addition to the blocking API on `Cluster`, the SDK provides asyncio and Twisted APIs on `ACluster` or `TxCluster` respectively.
If you are in doubt of which API to use, we recommend looking at the asyncio API first.

Simple queries with both asyncio and Twisted APIs look similar to the blocking one:

.ACouchbase
[source,python]
----
include::howtos:example$acouchbase_analytics_ops.py[tag=simple_query]
----

.TxCouchbase
[source,python]
----
include::howtos:example$txcouchbase_analytics_ops.py[tag=simple_query]
----

== Scoped Queries on Named Collections

In addition to creating a dataset with a WHERE clause to filter the results to documents with certain characteristics, SDK 3.2 now allows you to create a dataset against a named collection, for example:

[source,n1ql]
----
ALTER COLLECTION `travel-sample`.inventory.airport ENABLE ANALYTICS;

-- NB: this is more or less equivalent to:
CREATE DATAVERSE `travel-sample`.inventory;
CREATE DATASET `travel-sample`.inventory.airport ON `travel-sample`.inventory.airport;
----

We can then query the Dataset as normal, using the fully qualified keyspace:

[source,python]
----
include::howtos:example$analytics_ops.py[tag=handle_collection]
----

Note that using the `CREATE DATASET` syntax we could choose any Dataset name in any Dataverse, including the default.
However the SDK supports this standard convention, allowing us to query from the Scope object:

[source,python]
----
include::howtos:example$analytics_ops.py[tag=handle_scope]
----
